{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6141d9d",
   "metadata": {},
   "source": [
    "# Differentiable Uncalibrated Imaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dc9f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torchkbnufft as tkbn\n",
    "from skimage.data import shepp_logan_phantom\n",
    "from skimage.transform import resize\n",
    "from tqdm import tqdm\n",
    "# import torchviz\n",
    "from sigpy.mri.sim import birdcage_maps\n",
    "from scipy.ndimage import label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8c2331",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "resolution = (64, 64)\n",
    "num_coils = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5378b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_phantom(resolution):\n",
    "    image = shepp_logan_phantom().astype(np.float32)  # Shape format (H,W)\n",
    "    image = resize(image, resolution, anti_aliasing=True)\n",
    "    image = torch.tensor(image, dtype=torch.float)\n",
    "    image = (image + 1j * torch.zeros_like(image)).unsqueeze(0).unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "def init_kcoords(resolution, accel=2):\n",
    "    kcoords = torch.rand(int(resolution[0] * resolution[1] / accel), 2) * 2 * np.pi - np.pi    \n",
    "    return kcoords\n",
    "\n",
    "def cpx2dim(x): return torch.cat([x.real, x.imag], dim=1)\n",
    "def dim2cpx(x): return x[:,:num_coils] + 1j*x[:,num_coils:]\n",
    "\n",
    "def conjdot(a, b): return (a.conj() * b).sum().abs()\n",
    "\n",
    "def set_background_sensitivity_to_zero(csm, image_gt):\n",
    "    image_copy = image_gt.clone().cpu().numpy()\n",
    "    image_copy[:, :, resolution[0]//4:resolution[0]*3//4, resolution[1]//4:resolution[1]*3//4] = 1\n",
    "    labelmap, _ = label(image_copy > 0)\n",
    "    fg = labelmap != 0\n",
    "    fg = torch.tensor(fg, device=device)\n",
    "    csm = fg * csm\n",
    "    return csm, fg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b29aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FourierFeaturesEncoder(nn.Module):\n",
    "  \"\"\"\n",
    "  Fourier features encoder.\n",
    "  Module adapted from: https://github.com/swing-research/differentiable_uncalibrated_imaging/blob/main/models/implicit_neural.py\n",
    "  \"\"\"\n",
    "  def __init__(self, ffenc_size_multiplier=10):\n",
    "    super().__init__()\n",
    "    self.coeffs = (torch.arange(1, ffenc_size_multiplier + 1e-12) * math.pi * 0.5).to(device)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.kron(self.coeffs, x)\n",
    "    return torch.hstack((torch.sin(x), torch.cos(x)))\n",
    "\n",
    "\n",
    "class MeasurementRepr(nn.Module):\n",
    "  \"\"\"\n",
    "  Measurement representation model.\n",
    "  Module adapted from: https://github.com/swing-research/differentiable_uncalibrated_imaging/blob/main/models/implicit_neural.py\n",
    "  \"\"\"\n",
    "  def __init__(self, in_features=2, hidden_features=256, hidden_blocks=6, out_features=8, ffenc_size_multiplier=10):\n",
    "    \n",
    "    super().__init__()\n",
    "\n",
    "    self.ff_encoder = FourierFeaturesEncoder(ffenc_size_multiplier)\n",
    "    ffm_expansion_size = 2 * in_features * ffenc_size_multiplier\n",
    "\n",
    "    self.blocks = nn.ModuleList()\n",
    "    self.blocks.append(nn.Sequential(\n",
    "       nn.Linear(ffm_expansion_size, hidden_features), nn.ReLU(),\n",
    "       nn.Linear(hidden_features, hidden_features),  nn.ReLU()))\n",
    "    for _ in range(hidden_blocks-1):\n",
    "      self.blocks.append(nn.Sequential(\n",
    "         nn.Linear(hidden_features + ffm_expansion_size, hidden_features), nn.ReLU(),\n",
    "         nn.Linear(hidden_features, hidden_features), nn.ReLU()))\n",
    "\n",
    "    self.out_block = nn.Sequential(\n",
    "       nn.Linear(hidden_features + ffm_expansion_size, hidden_features), nn.ReLU(),\n",
    "       nn.Linear(hidden_features, int(hidden_features / 2)), nn.ReLU(),\n",
    "       nn.Linear(int(hidden_features / 2), out_features))      \n",
    "\n",
    "  def forward(self, coords):  # Shape: (ksamples, 2)\n",
    "    fourier_features = self.ff_encoder(coords)\n",
    "    x = fourier_features\n",
    "    for block in self.blocks:\n",
    "      x = block(x)\n",
    "      x = torch.cat((x, fourier_features), dim=1)\n",
    "    out = self.out_block(x)\n",
    "    out = dim2cpx(out)  # Shape: (ksamples, coils); Dtype = complex64\n",
    "    return out\n",
    "\n",
    "\n",
    "class ForwardOperator:\n",
    "\n",
    "    \"\"\" SENSE operator \"\"\"\n",
    "\n",
    "    def __init__(self, csm=None, device='cpu'):\n",
    "        self.nufft = tkbn.KbNufft(im_size=resolution, device=device)\n",
    "        self.inufft = tkbn.KbNufftAdjoint(im_size=resolution, device=device)        \n",
    "        self.csm = csm\n",
    "\n",
    "    def set_coords(self, kcoords):\n",
    "        self.kcoords = kcoords.T\n",
    "        self.interp_matrices = tkbn.calc_tensor_spmatrix(self.kcoords.clone().detach(), im_size=resolution)\n",
    "        self.interp_matrices = (self.interp_matrices[0].to(kcoords.device), self.interp_matrices[1].to(kcoords.device))\n",
    "\n",
    "    def __call__(self, image): \n",
    "        kdata = self.nufft(image, self.kcoords, smaps=self.csm)  # Shape: (1, coils, ksamples); Dtype = complex64\n",
    "        kdata = kdata.squeeze(0).T  # Shape: (ksamples, coils); Dtype = complex64\n",
    "        return kdata\n",
    "    \n",
    "    def H(self, kdata):              # Shape: (ksamples, 1); Dtype = complex64\n",
    "        kdata = kdata.T.unsqueeze(0) # Shape: (1, 1, ksamples); Dtype = complex64\n",
    "        image = self.inufft(kdata, self.kcoords, self.interp_matrices, smaps=self.csm)  # Shape: (1, 1, H, W); Dtype = complex64\n",
    "        return image\n",
    "\n",
    "\n",
    "class ReconstructorSimple:\n",
    "    def __call__(self, kdata, A): return A.H(kdata)\n",
    "\n",
    "\n",
    "class ReconstructorCGSENSE:\n",
    "    \"\"\" CG-SENSE reconstruction \"\"\"\n",
    "    def __call__(self, kdata, A):\n",
    "      a = A.H(kdata)\n",
    "      b = torch.zeros_like(a)\n",
    "      p = a.clone()\n",
    "      r = a.clone()\n",
    "      rdotr_prev = conjdot(r, r)\n",
    "      for _ in range(10):          \n",
    "        q = A.H(A(p))\n",
    "        b = b + (rdotr_prev / conjdot(p, q)) * p\n",
    "        r = r - (rdotr_prev / conjdot(p, q)) * q\n",
    "        rdotr = conjdot(r, r)\n",
    "        p = r + (rdotr / rdotr_prev) * p          \n",
    "        rdotr_prev = rdotr\n",
    "      return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794e1d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init stuff\n",
    "image_gt = init_phantom(resolution).to(device)         # Shape: (1, 1, H, W); Dtype = complex64\n",
    "csm = torch.tensor(birdcage_maps((num_coils, resolution[0], resolution[1]), r=1.1, dtype=np.complex64), device=device)  # Shape format (C,H,W)\n",
    "csm, fg = set_background_sensitivity_to_zero(csm, image_gt)\n",
    "\n",
    "R = MeasurementRepr().to(device)\n",
    "A = ForwardOperator(csm, device)\n",
    "# G = ReconstructorSimple()\n",
    "G = ReconstructorCGSENSE()\n",
    "\n",
    "kcoords_true = init_kcoords(resolution, accel=1.5).to(device)   # Shape: (ksamples, 2)\n",
    "A.set_coords(kcoords_true)\n",
    "kdata_true = A(image_gt).clone().detach()  # Shape: (ksamples, 1); Dtype = complex64\n",
    "\n",
    "# Simulate miscalibration\n",
    "kcoords_miscalib = kcoords_true + torch.randn_like(kcoords_true) * torch.pi * 0.01\n",
    "kcoords_miscalib = torch.clip(kcoords_miscalib, -torch.pi, torch.pi)\n",
    "kcoords = kcoords_miscalib.clone().detach().to(device)\n",
    "kcoords.requires_grad = True\n",
    "\n",
    "# Sanity check\n",
    "A.set_coords(kcoords_miscalib); recon_uncorrected = G(kdata_true, A)\n",
    "A.set_coords(kcoords_true);     recon_true = G(kdata_true, A)\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "axs[0].imshow(recon_uncorrected.abs().squeeze().detach().cpu()); axs[0].set_title(\"Recon: uncorrected\")\n",
    "axs[1].imshow(recon_true.abs().squeeze().detach().cpu()); axs[1].set_title(\"Recon: truth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b97fb6a",
   "metadata": {},
   "source": [
    "### Test framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e441bb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fitting(kdata, kdata_pred_r):             return torch.norm(kdata - kdata_pred_r, p=2)\n",
    "def loss_consistency(kdata_pred_r, kdata_pred_ag): return torch.norm(kdata_pred_r - kdata_pred_ag, p=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455ba93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization prep\n",
    "params = itertools.chain([kcoords], R.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=1e-4)\n",
    "consistency_weight = 1e-1\n",
    "\n",
    "# Optimization loop\n",
    "num_iters = 5\n",
    "loss_history = []\n",
    "kcoord_errors = []\n",
    "for it in tqdm(range(num_iters)):\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    A.set_coords(kcoords)\n",
    "    kdata_pred_r = R(kcoords)  # Shape: {ksamples, 1}\n",
    "    kdata_pred_ag = A(G(kdata_pred_r, A))  # Shape: {ksamples, 1}\n",
    "    loss = loss_fitting(kdata_true, kdata_pred_r) + consistency_weight * loss_consistency(kdata_pred_r, kdata_pred_ag)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_history.append(loss.item())\n",
    "    kcoord_errors.append(F.mse_loss(kcoords.clone().detach(), kcoords_true).item())\n",
    "\n",
    "\n",
    "# Results\n",
    "print(loss_history[-1])\n",
    "print(kcoord_errors[-1])\n",
    "# plt.plot(kcoord_errors); plt.show()\n",
    "\n",
    "A.set_coords(kcoords_miscalib); recon_uncorrected_inr = G(R(kcoords_miscalib), A)\n",
    "A.set_coords(kcoords);          recon_corrected_inr = G(R(kcoords), A)\n",
    "A.set_coords(kcoords_true);     recon_true = G(kdata_true, A)\n",
    "\n",
    "fig, axs = plt.subplots(1, 5, figsize=(24, 4))\n",
    "axs[0].plot(loss_history); axs[0].set_title(\"Loss\")\n",
    "axs[1].imshow(recon_uncorrected.abs().squeeze().detach().cpu()); axs[1].set_title(\"Recon: uncorrected\")\n",
    "axs[2].imshow(recon_uncorrected_inr.abs().squeeze().detach().cpu()); axs[1].set_title(\"Recon: uncorrected + INR\")\n",
    "axs[3].imshow(recon_corrected_inr.abs().squeeze().detach().cpu()); axs[2].set_title(\"Recon: corrected + INR\")\n",
    "axs[4].imshow(recon_true.abs().squeeze().detach().cpu()); axs[3].set_title(\"Recon: truth\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7ca569",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roci2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
